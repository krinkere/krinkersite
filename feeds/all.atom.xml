<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Cloud. Big Data. Analytics... and so on</title><link href="https://krinkere.github.io/krinkersite/" rel="alternate"></link><link href="https://krinkere.github.io/krinkersite/feeds/all.atom.xml" rel="self"></link><id>https://krinkere.github.io/krinkersite/</id><updated>2018-04-03T13:46:00-04:00</updated><entry><title>Mapping SQL to Pandas</title><link href="https://krinkere.github.io/krinkersite/mapping_sql_to_pandas.html" rel="alternate"></link><published>2018-04-03T13:15:00-04:00</published><updated>2018-04-03T13:46:00-04:00</updated><author><name>Al Krinker</name></author><id>tag:krinkere.github.io,2018-04-03:/krinkersite/mapping_sql_to_pandas.html</id><summary type="html">&lt;p&gt;Illustration of common SQL operations mapped to Pandas.&lt;/p&gt;</summary><content type="html">&lt;style&gt;
.table-borders td,
.table-borders th
{
    border: 1px solid black;
    padding: 10px;
}

span.bold-red {
    color: red;
    font-weight: bold;
}

&lt;/style&gt;

&lt;table class="table-borders"&gt;
    &lt;tr&gt;
            &lt;th bgcolor="gray"&gt;SQL&lt;/th&gt;
            &lt;th bgcolor="gray"&gt;Pandas&lt;/th&gt;
     &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;
                select&lt;br&gt;
                *&lt;br&gt;
                from table_name
             &lt;/td&gt;
            &lt;td&gt;df&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;
                select&lt;br&gt;
                *&lt;br&gt;
                from table_name&lt;br&gt;
                &lt;span class="bold-red"&gt;limit&lt;/span&gt; 3&lt;/td&gt;
            &lt;td&gt;df.head(3)&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;
                select&lt;br&gt;
                col_name_1&lt;br&gt;
                from table_name&lt;br&gt;
                &lt;span class="bold-red"&gt;where&lt;/span&gt; col_name_2 = 'value'&lt;/td&gt;
            &lt;td&gt;df[df.col_name_2 == 'value'].col_name_1&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;
                select&lt;br&gt;
                &lt;span class="bold-red"&gt;distinct&lt;/span&gt; col_name_1&lt;br&gt;
                from table_name&lt;/td&gt;
            &lt;td&gt;df.col_name_1.unique()&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;
                select&lt;br&gt;
                *&lt;br&gt;
                 from table_name&lt;br&gt;
                 where col_name_1 = 'val_1' &lt;span class="bold-red"&gt;and&lt;/span&gt; col_name_2 = 'val_2'&lt;/td&gt;
            &lt;td&gt;df[(df.col_name_1 == 'val_1') &amp; (df.col_name_2 == 'val_2')]&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;select&lt;br&gt;
            col_name_1, col_name_3, col_name_3&lt;br&gt;
            from table_name&lt;br&gt;
            where col_name_4 = 'val_1' &lt;span class="bold-red"&gt;and&lt;/span&gt; col_name_5 = 'val_2'&lt;/td&gt;
            &lt;td&gt;df[(df.col_name_4 == 'val_1') &amp; (df.col_name_5 == 'val_2')][['col_name_1', 'col_name_2', 'col_name_3']]&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;select&lt;br&gt;
            *&lt;br&gt;
            from table_name&lt;br&gt;
            where col_name_1 = 'value'&lt;br&gt;
            &lt;span class="bold-red"&gt;order by&lt;/span&gt; col_name_2&lt;/td&gt;
            &lt;td&gt;df[df.col_name_1 == 'value'].sort_values('col_name_2')&lt;/td&gt;
        &lt;/tr&gt;
         &lt;tr&gt;
            &lt;td&gt;select&lt;br&gt;
            *&lt;br&gt;
            from table_name&lt;br&gt;
            where col_name_1 = 'value'&lt;br&gt;
            &lt;span class="bold-red"&gt;order by&lt;/span&gt; col_name_2 &lt;span class="bold-red"&gt;desc&lt;/span&gt;&lt;/td&gt;
            &lt;td&gt;df[df.col_name_1 == 'value'].sort_values('col_name_2', ascending=False)&lt;/td&gt;
        &lt;/tr&gt;        
        &lt;tr&gt;
            &lt;td&gt;select&lt;br&gt;
            *&lt;br&gt;
            from table_name&lt;br&gt;
            where col_name &lt;span class="bold-red"&gt;in&lt;/span&gt; ('val_1', 'val_2')&lt;/td&gt;
            &lt;td&gt;df[df.col_name.isin(['val_1', 'val_2'])]&lt;/td&gt;
        &lt;/tr&gt;        
        &lt;tr&gt;
            &lt;td&gt;select&lt;br&gt;
            *&lt;br&gt;
            from table_name&lt;br&gt;
            where col_name &lt;span class="bold-red"&gt;not in&lt;/span&gt; ('val_1', 'val_2')&lt;/td&gt;
            &lt;td&gt;df[~df.col_name.isin(['val_1', 'val_2'])]&lt;/td&gt;
        &lt;/tr&gt;   
        &lt;tr&gt;
            &lt;td&gt;select&lt;br&gt;
            col_name_1, col_name_2, count(&amp;ast;)&lt;br&gt;
            from table_name&lt;br&gt;
            &lt;span class="bold-red"&gt;group by&lt;/span&gt; col_name_1, col_name_2&lt;br&gt;
            &lt;span class="bold-red"&gt;order by&lt;/span&gt; col_name_1, col_name_2&lt;/td&gt;
            &lt;td&gt;df.groupby(['col_name_1', 'col_name_2']).size()&lt;/td&gt;
        &lt;/tr&gt;         
        &lt;tr&gt;
            &lt;td&gt;select&lt;br&gt;
            col_name_1, col_name_2, count(&amp;ast;)&lt;br&gt;
            from table_name&lt;br&gt;
            &lt;span class="bold-red"&gt;group by&lt;/span&gt; col_name_1, col_name_2&lt;br&gt;
            &lt;span class="bold-red"&gt;order by&lt;/span&gt; col_name_1, count(&amp;ast;) desc&lt;/td&gt;
            &lt;td&gt;df.groupby(['col_name_1', 'col_name_2']).size().to_frame('size').reset_index().sort_values(['col_name_1', 'size'], ascending=[True, False])&lt;/td&gt;
        &lt;/tr&gt;      
        &lt;tr&gt;
            &lt;td&gt;select&lt;br&gt;
            col_name_1, count(&amp;ast;)&lt;br&gt;
            from table_name&lt;br&gt;
            where col_name_2 = 'val_1'&lt;br&gt;
            group by col_name_1&lt;br&gt;
            &lt;span class="bold-red"&gt;having&lt;/span&gt; count(&amp;ast;) &gt; 1000&lt;br&gt;
            order by count(&amp;ast;) desc&lt;/td&gt;
            &lt;td&gt;df[df.col_name_2 == 'val_1'].groupby('col_name_1').filter(lambda g: len(g) &gt; 1000).groupby('col_name_1').size().sort_values(ascending=False)&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;select&lt;br&gt;
            col_name&lt;br&gt;
            from table_name&lt;br&gt;
            order by size&lt;br&gt;
            &lt;span class="bold-red"&gt;desc limit&lt;/span&gt; 10&lt;/td&gt;
            &lt;td&gt;df.nlargest(10, columns='col_name')&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;select&lt;br&gt;
            col_name&lt;br&gt;
            from table_name&lt;br&gt;
            order by size&lt;br&gt;
            &lt;span class="bold-red"&gt;desc limit&lt;/span&gt; 10
            &lt;span class="bold-red"&gt;offset 10&lt;/span&gt;&lt;/td&gt;
            &lt;td&gt;df.nlargest(&lt;span class="bold-red"&gt;20&lt;/span&gt;, columns='col_name').tail(10)&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;select&lt;br&gt;
            &lt;span class="bold-red"&gt;max&lt;/span&gt;(col_name), &lt;span class="bold-red"&gt;min&lt;/span&gt;(col_name), &lt;span class="bold-red"&gt;mean&lt;/span&gt;(col_name), &lt;span class="bold-red"&gt;median&lt;/span&gt;(col_name)&lt;br&gt;
            from table_name&lt;/td&gt;
            &lt;td&gt;df.agg({'col_name': ['min', 'max', 'mean', 'median']})&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;select&lt;br&gt;
            col_name_1, col_name_2, col_name_3, col_name_4&lt;br&gt;
            from table_name_1&lt;br&gt;
            &lt;span class="bold-red"&gt;join&lt;/span&gt; table_name_2&lt;br&gt;
            on table_name_1.col_name_id_1 = table_name_2.col_name_id_2&lt;br&gt;
            where table_name_2.col_name = 'val'&lt;/td&gt;
            &lt;td&gt;df1.merge(df2[df2.col_name == 'val'][['col_name_id_2']], left_on='col_name_id_1', right_on='col_name_id_2', how='inner')[['col_name_1', 'col_name_2', 'col_name_3', 'col_name_4']]&lt;/td&gt;
        &lt;/tr&gt;        
        &lt;tr&gt;
            &lt;td&gt;
                &lt;span class="bold-red"&gt;create&lt;/span&gt; table table_name (col_name_1 integer, col_name_2 text);&lt;br&gt;
                &lt;span class="bold-red"&gt;insert&lt;/span&gt; into table_name values (1, 'val_1');&lt;br&gt;
                insert into table_name values (2, 'val_2');&lt;br&gt;
                insert into table_name values (3, 'val_3');
            &lt;/td&gt;
            &lt;td&gt;
                df1 = pd.DataFrame({'id': [1, 2], 'name': ['val_1', 'val_2']})&lt;br&gt;
                df2 = pd.DataFrame({'id': [3], 'name': ['val_3']})&lt;br&gt;
                pd.concat([df1, df2]).reset_index(drop=True)
            &lt;/td&gt;
        &lt;/tr&gt;        
        &lt;tr&gt;
            &lt;td&gt;&lt;span class="bold-red"&gt;update&lt;/span&gt;&lt;br&gt;
            table_name&lt;br&gt;
            set col_name_1 = 'val_1'&lt;br&gt;
            where col_name_2 == 'val_2'&lt;/td&gt;
            &lt;td&gt;df.loc[df['col_name_2'] == 'val_2', 'col_name_1'] = 'val_1'&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;span class="bold-red"&gt;delete&lt;/span&gt;&lt;br&gt;
            from table_name&lt;br&gt;
            where col_name = 'val'&lt;/td&gt;
            &lt;td&gt;
                df = df[df.col_name != 'val'&lt;br&gt;
                df.drop(df[df.col_name == 'val'].index)
            &lt;/td&gt;
        &lt;/tr&gt;
&lt;/table&gt;</content><category term="python"></category><category term="pandas"></category></entry><entry><title>How to remove typos from entity names via fuzzywuzzy module in python.</title><link href="https://krinkere.github.io/krinkersite/fix_spelling_errors.html" rel="alternate"></link><published>2018-03-30T11:44:00-04:00</published><updated>2018-03-30T11:44:00-04:00</updated><author><name>Al Krinker</name></author><id>tag:krinkere.github.io,2018-03-30:/krinkersite/fix_spelling_errors.html</id><summary type="html">&lt;p&gt;Remove typos by leveraging fuzzywuzzy module in python&lt;/p&gt;</summary><content type="html">&lt;p&gt;While cleaning data in csv file, it is often common to see entity name such 
as city, person name, organization, etc being misspelled a little slightly and 
hence not producing same type of statistic as you might want. For example, 
let's say that you try to collect stats on number of times user accessed your page.
In that user name can be entered manually or it provided by different systems, 
then it might be different slight. Here I mean that we need to ensure that
case is the same not to throw our stats and any spaces are cleaned as well
just as a prelim step. Also, the username might be slightly misspelled with an
extra dash, space or single character. Here lays the danger though, there
can we two usernames that vary just by a character. I remember the days of hotmail
and that you would often get emails sent to blackwolf to your black.wolf account.
Gmail saw this as a problem and now it ignores periods in the emails to avoid this
issue. What I am trying to say is that you need to use typos with care. Now how you do it?&lt;/p&gt;
&lt;p&gt;First of all, clean the text from spaces and make it lowercased.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;

&lt;span class="c1"&gt;# read in our dataset&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;my_data.csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# convert to lower case&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;username&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;username&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c1"&gt;# remove trailing white spaces&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;username&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;username&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# let&amp;#39;s take a look at list of unique usernames values&lt;/span&gt;
&lt;span class="n"&gt;username&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;username&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# sort them alphabetically and then take a closer look&lt;/span&gt;
&lt;span class="n"&gt;username&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sort&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;username&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We should see some usernames that seem too close of a match... let's 
try to find all usernames that are more that 90% close to each other 
and replace them to the most common name&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;fuzzywuzzy&lt;/span&gt;

&lt;span class="c1"&gt;# function to replace rows in the provided column of the provided dataframe&lt;/span&gt;
&lt;span class="c1"&gt;# that match the provided string above the provided ratio with the provided string&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;replace_matches_in_column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;string_to_match&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_ratio&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;90&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# get a list of unique strings&lt;/span&gt;
    &lt;span class="n"&gt;strings&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="c1"&gt;# get the top 10 closest matches to our input string&lt;/span&gt;
    &lt;span class="n"&gt;matches&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fuzzywuzzy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;process&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;string_to_match&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;strings&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                         &lt;span class="n"&gt;limit&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;scorer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fuzzywuzzy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fuzz&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;token_sort_ratio&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# only get matches with a ratio &amp;gt; 90&lt;/span&gt;
    &lt;span class="n"&gt;close_matches&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;matches&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;matches&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;matches&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;matches&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;min_ratio&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="c1"&gt;# get the rows of all the close matches in our dataframe&lt;/span&gt;
    &lt;span class="n"&gt;rows_with_matches&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;close_matches&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# replace all rows with close matches with the input matches &lt;/span&gt;
    &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;rows_with_matches&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;string_to_match&lt;/span&gt;

    &lt;span class="c1"&gt;# let us know the function&amp;#39;s done&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;All done!&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now you can call it as such&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# use the function we just wrote to replace close matches to &amp;quot;d.i khan&amp;quot; with &amp;quot;d.i khan&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;replace_matches_in_column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;username&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;string_to_match&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;black.wolf&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All done!&lt;/p&gt;</content><category term="python"></category></entry><entry><title>How to detect encoding of CSV file in python</title><link href="https://krinkere.github.io/krinkersite/encoding_csv_file_python.html" rel="alternate"></link><published>2018-03-30T09:27:00-04:00</published><updated>2018-03-30T09:27:00-04:00</updated><author><name>Al Krinker</name></author><id>tag:krinkere.github.io,2018-03-30:/krinkersite/encoding_csv_file_python.html</id><summary type="html">&lt;p&gt;How to read CSV file in python and detect its encoding&lt;/p&gt;</summary><content type="html">&lt;p&gt;In my line of work, I have to deal with a lot of spreadsheets coming 
my way with different type of data. I don't control these csv files, hence
I never know how they are being generated. If I were to simply read
the file, I would often get something like that.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;UnicodeDecodeError Traceback (most recent call last)
    pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader._convert_tokens()
    pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader._convert_with_dtype()
    pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader._string_convert()
    pandas/_libs/parsers.pyx in pandas._libs.parsers._string_box_utf8()

UnicodeDecodeError: &amp;#39;utf-8&amp;#39; codec can&amp;#39;t decode byte 0x99 in position 11: invalid start byte
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Basically, when you specify the following, you assume that the information
was encoded in UTF-8 ()default) format &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;my_data.csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;However, if that's not the case and format is not UTF-8 then you get a nasty error 
shown previously. What to do? Try manually some common encoders, or look at the file
and try to figure it out? &lt;br/&gt;
A much better way is to use chardet module to do it for you. Here we going to 
read first ten thousand bytes to figure out the encoding type. Note that chardet
is not 100% accurate and you would actually see the level of confidence of 
encoder detection as part of chardet output. But it is still better than guessing manually.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# look at the first ten thousand bytes to guess the character encoding&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;my_data.csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;rb&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;rawdata&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;chardet&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;detect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rawdata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10000&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# check what the character encoding might be&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The result is&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;{&amp;#39;encoding&amp;#39;: &amp;#39;Windows-1252&amp;#39;, &amp;#39;confidence&amp;#39;: 0.73, &amp;#39;language&amp;#39;: &amp;#39;&amp;#39;}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So chardet is 73% confidence that the right encoding is "Windows-1252".  Now we can use
this data to specify encoding type as we trying to read the file&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;my_data.csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;encoding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Windows-1252&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;No errors! &lt;/p&gt;</content><category term="python"></category></entry><entry><title>Commit your changes or stash them before you can merge??!?!</title><link href="https://krinkere.github.io/krinkersite/Commit_your_changes_or_stash_them_before_you_can_merge.html" rel="alternate"></link><published>2018-03-09T07:54:00-05:00</published><updated>2018-03-09T08:17:00-05:00</updated><author><name>Al Krinker</name></author><id>tag:krinkere.github.io,2018-03-09:/krinkersite/Commit_your_changes_or_stash_them_before_you_can_merge.html</id><summary type="html">&lt;p&gt;What to do when you are faced with 'Please, commit your changes or stash them before you can merge.' message from git as you are trying to get latest code off your remote repository&lt;/p&gt;</summary><content type="html">&lt;p&gt;When trying to update your local copy from remote master copy, you will see following error&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; git pull origin master
&lt;span class="go"&gt;error: Your local changes to the following files would be overwritten by merge:&lt;/span&gt;
&lt;span class="go"&gt;&amp;lt;list of files&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;Please commit your changes or stash them before you merge.&lt;/span&gt;
&lt;span class="go"&gt;Aborting&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You have several options here&lt;/p&gt;
&lt;h3&gt;Commit the change&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; git add .
&lt;span class="gp"&gt;$&lt;/span&gt; git commit -m &lt;span class="s2"&gt;&amp;quot;committing before the update&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Stash them&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; git stash
&lt;span class="gp"&gt;$&lt;/span&gt; git stash pop
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Overwrite local changes&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="go"&gt;git reset --hard&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="git"></category></entry><entry><title>How to check in a folder, but ignore its contents</title><link href="https://krinkere.github.io/krinkersite/check_in_folder_ignore_contents.html" rel="alternate"></link><published>2016-09-08T10:52:00-04:00</published><updated>2018-03-16T14:08:00-04:00</updated><author><name>Al Krinker</name></author><id>tag:krinkere.github.io,2016-09-08:/krinkersite/check_in_folder_ignore_contents.html</id><summary type="html">&lt;p&gt;Check in folder into git, but ignore any contents in it (massive logs, models, etc)&lt;/p&gt;</summary><content type="html">&lt;p&gt;Git does not let you to check in an empty folder, even if you are using it as a temp output location. How to work around it?&lt;/p&gt;
&lt;p&gt;In the folder that you are trying to commit, create &lt;b&gt;.gitignore&lt;/b&gt; file and add following content&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ast;&lt;br/&gt;
&amp;ast;/&lt;br/&gt;
!.gitignore&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;then add it to the git&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; git add .gitignore
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &amp;ast; line tells git to ignore all files in the folder, but !.gitignore tells git to still include the .gitignore file. This way, your local repository and any other clones of the repository all get both the empty folder and the .gitignore it needs.
May be obvious but also add &amp;ast;/ to the git ignore to also ignore sub folders.&lt;/p&gt;</content><category term="git"></category></entry><entry><title>How to back off back to the earlier version of the code</title><link href="https://krinkere.github.io/krinkersite/back_it_off.html" rel="alternate"></link><published>2016-07-29T11:44:00-04:00</published><updated>2018-03-16T15:00:00-04:00</updated><author><name>Al Krinker</name></author><id>tag:krinkere.github.io,2016-07-29:/krinkersite/back_it_off.html</id><summary type="html">&lt;p&gt;How to get back to previous good commit&lt;/p&gt;</summary><content type="html">&lt;p&gt;Say you are developing a new feature and you realize after few commits that you went off to a way different route that you suppose to and you need to back it up few commits and start over... this definitely would be a cleaner way vs trying to remove what was done manually. How to do it though?&lt;/p&gt;
&lt;p&gt;Check out what you want and get rid of all that code...&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; git reset --hard 0d3b7ac32
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then you would push it up&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; git push origin +master
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Pretty simple once you know it.&lt;/p&gt;</content><category term="git"></category></entry><entry><title>How to remove files added to git</title><link href="https://krinkere.github.io/krinkersite/How_to_remove_files_added_to_git.html" rel="alternate"></link><published>2016-03-07T21:34:00-05:00</published><updated>2018-03-16T13:51:00-04:00</updated><author><name>Al Krinker</name></author><id>tag:krinkere.github.io,2016-03-07:/krinkersite/How_to_remove_files_added_to_git.html</id><summary type="html">&lt;p&gt;How to remove files added to git via git add . command&lt;/p&gt;</summary><content type="html">&lt;p&gt;Imagine the situation where you wrote your code and then decided to add it to your git repo. Pretty easy right?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; git init
&lt;span class="gp"&gt;$&lt;/span&gt; git add .
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Before you commit, you want to see what's going to be committed. So you do&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; git status
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now you see whole bunch of config and target files that have no business being in the repo. Not a problem, you can use .gitignore right? First remove what you added, create .gitignore file and you can re add again only source files.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; git rm -r .
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;create .gitignore with&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;/target/&amp;ast;&amp;ast;&lt;br/&gt;
.settings/&amp;ast;&amp;ast;&lt;br/&gt;
.classpath&lt;br/&gt;
.project&lt;br/&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;and re-add&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; git add .
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Check what's about to be committed... and what?!?!? old files? How can this be? Did I messed up my regex? spelled gitignore wrong or forgot the leading period? Nope, everything seems correct...&lt;/p&gt;
&lt;p&gt;After reading gitignore help guide... you need to clear your cache!!! Here is what you do&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; git rm -r --cached .
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;cached flag is the key difference.&lt;/p&gt;
&lt;p&gt;After this command, re-add, verify and finally commit:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; git add .
&lt;span class="gp"&gt;$&lt;/span&gt; git commit -m &lt;span class="s2"&gt;&amp;quot;source files only!!!&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="git"></category></entry><entry><title>Accessing wired Windows printer from your Mac</title><link href="https://krinkere.github.io/krinkersite/Accessing_wired_Windows_printer_from_your_Mac.html" rel="alternate"></link><published>2015-12-20T12:52:00-05:00</published><updated>2018-03-15T15:46:00-04:00</updated><author><name>Al Krinker</name></author><id>tag:krinkere.github.io,2015-12-20:/krinkersite/Accessing_wired_Windows_printer_from_your_Mac.html</id><summary type="html">&lt;p&gt;What to do when you are faced with 'Please, commit your changes or stash them before you can merge.' message from git as you are trying to get latest code off your remote repository&lt;/p&gt;</summary><content type="html">&lt;p&gt;Before my PC seized to be, I used to have old wired printer that did the job... the only problem was that I already have few Apple laptops and I wanted to be able to print from them (The problem is easily solved by buying wireless printer that supports AirPrint, i.e. even print from your iPhone!).&lt;/p&gt;
&lt;p&gt;Anyway, if you have wired Windows printer and don't want to upgrade just yet here is what you need to do:&lt;/p&gt;
&lt;p&gt;On Windows PC&lt;br /&gt;
1. Establish user account on your PC. This was one thing that I had to do to make everything that should work to actually work. This is as easy as opening your control panel and clicking on Add user in your Users menu. For more tricks see this: http://www.howtogeek.com/howto/10325/manage-user-accounts-in-windows-home-server/&lt;br /&gt;
2. Now onto actual set up... Select Start-&amp;gt;Devices and Printers. Right click on the printer that you want to share, and either pick share or properties and then pick sharing tab. Make sure that share check box is selected and make sure that you note down the name of the printer.&lt;br /&gt;
3. Open command prompt. Use ipconfig command to find your PC's IP.&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;To summarize this part. You have IP address and name of the printer to connect to and you have the credentials that you created in step 1.&lt;/p&gt;
&lt;p&gt;On MAC&lt;br /&gt;
1. Open System Preferences and locate Printers and Scanners icon. Click!&lt;br /&gt;
2. Select + under printers to add new printer, i.e. wired Windows printer.&lt;br /&gt;
3. Right click on the menu and select Customize Toolbar and add Advanced&lt;br /&gt;
4. Click on Advanced. For type select Windows printer via spoolss&lt;br /&gt;
5. For URL provide IP and printer name that you have... so the link looks like smb://192.138.1.13/printer_name (Replace any spaces with %20 in your&lt;br /&gt;
6. Under Choose a driver or Printer Model pick your printer type (I did not see my exact model so I picked closes HP model instead. Worked)&lt;br /&gt;
7. At this point your PC printer will be connected to your Mac.&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;Testing&lt;br /&gt;
Select something to print on your Mac... in my case, the first time it tried to print it asked for my PC username/password which we created previously, after that it was stored in my keychain and was never an issue again.&lt;/p&gt;
&lt;p&gt;That's it! Hope it helps and once again, let me know if you have further questions, etc.&lt;/p&gt;</content><category term="hardware"></category><category term="mac"></category></entry><entry><title>Lucene scoring examplained</title><link href="https://krinkere.github.io/krinkersite/Lucene_scoring_examplained.html" rel="alternate"></link><published>2015-04-30T19:48:00-04:00</published><updated>2018-03-15T12:30:00-04:00</updated><author><name>Al Krinker</name></author><id>tag:krinkere.github.io,2015-04-30:/krinkersite/Lucene_scoring_examplained.html</id><summary type="html">&lt;p&gt;Overview of Lucene scoring&lt;/p&gt;</summary><content type="html">&lt;p&gt;Several good books already explain what Lucene scoring really means and how it is calculated in great detail with lots of basic concepts explain.
In this, post I am going to try to keep it high level for people already familiar with the basics and go straight for the scoring overview.&lt;/p&gt;
&lt;p&gt;The factors involved in Lucene's scoring algorithm are as follows:&lt;br /&gt;
1. tf = term frequency in document = measure of how often a term appears in the document&lt;br /&gt;
2. idf = inverse document frequency = measure of how often the term appears across the index&lt;br /&gt;
3. coord = number of terms in the query that were found in the document&lt;br /&gt;
4. lengthNorm = measure of the importance of a term according to the total number of terms in the field&lt;br /&gt;
5. queryNorm = normalization factor so that queries can be compared&lt;br /&gt;
6. boost (index) = boost of the field at index-time&lt;br /&gt;
7. boost (query) = boost of the field at query-time&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;The implementation, implication and rationales of factors 1,2, 3 and 4 in DefaultSimilarity.java, which is what you get if you don't explicitly specify a similarity, are:
note: the implication of these factors should be read as, "Everything else being equal, … "&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;tf&lt;br /&gt;
Implementation: sqrt(freq)&lt;br /&gt;
Implication: the more frequent a term occurs in a document, the greater its score&lt;br /&gt;
Rationale: documents which contains more of a term are generally more relevant&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;idf&lt;br /&gt;
Implementation: log(numDocs/(docFreq+1)) + 1&lt;br /&gt;
Implication: the greater the occurrence of a term in different documents, the lower its score&lt;br /&gt;
Rationale: common terms are less important than uncommon ones&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;coord&lt;br /&gt;
Implementation: overlap / maxOverlap&lt;br /&gt;
Implication: of the terms in the query, a document that contains more terms will have a higher score&lt;br /&gt;
Rationale: self-explanatory&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;lengthNorm&lt;br /&gt;
Implementation: 1/sqrt(numTerms)&lt;br /&gt;
Implication: a term matched in fields with less terms have a higher score&lt;br /&gt;
Rationale: a term in a field with less terms is more important than one with more&lt;br /&gt;
queryNorm is not related to the relevance of the document, but rather tries to make scores between different queries comparable. It is implemented as 1/sqrt(sumOfSquaredWeights)&lt;br /&gt;
So, roughly speaking (quoting Mark Harwood from the mailing list),&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Documents containing all the search terms are good&lt;/li&gt;
&lt;li&gt;Matches on rare words are better than for common words&lt;/li&gt;
&lt;li&gt;Long documents are not as good as short ones&lt;/li&gt;
&lt;li&gt;Documents which mention the search terms many times are good&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The mathematical definition of the scoring can be found in &lt;a href="https://lucene.apache.org/core/2_9_4/api/all/org/apache/lucene/search/Similarity.html"&gt;org.apache.lucene.search.Class Similarity&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Customizing scoring&lt;/h3&gt;
&lt;p&gt;Its easy to customize the scoring algorithm. Just subclass DefaultSimilarity and override the method you want to customize.
For example, if you want to ignore how common a term appears across the index,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Similarity&lt;/span&gt; &lt;span class="n"&gt;sim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;DefaultSimilarity&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="nf"&gt;idf&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and if you think for the title field, more terms is better&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Similarity&lt;/span&gt; &lt;span class="n"&gt;sim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;DefaultSimilarity&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt; &lt;span class="nf"&gt;lengthNorm&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;field&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;numTerms&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;field&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;equals&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;title&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;Math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;log&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;numTerms&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="kd"&gt;super&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;lengthNorm&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;field&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;numTerms&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="lucene"></category><category term="search"></category></entry><entry><title>How to find a file containing particular text in Linux</title><link href="https://krinkere.github.io/krinkersite/How_to_find_a_file_containing_particular_text_in_Linux.html" rel="alternate"></link><published>2014-05-27T10:41:00-04:00</published><updated>2014-05-27T10:42:00-04:00</updated><author><name>Al Krinker</name></author><id>tag:krinkere.github.io,2014-05-27:/krinkersite/How_to_find_a_file_containing_particular_text_in_Linux.html</id><summary type="html">&lt;p&gt;Use grep to find file containing particular text.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Here is a quick example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; grep -r &lt;span class="s2"&gt;&amp;quot;text string to search” directory-path&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To search for a string ‘logged in’ in all text (*.log) files located in /etc/networks/ directory for example, use:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; grep &lt;span class="s2"&gt;&amp;quot;logged in&amp;quot;&lt;/span&gt; /etc/networks/*.log
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To search all subdirectories recursively, include -r option like so:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; grep -r &lt;span class="s2"&gt;&amp;quot;logged in&amp;quot;&lt;/span&gt; /etc/networks/*.log
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The grep command prints the matching lines for each match. Pass -H option to print the filename only:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; grep -H -r &lt;span class="s2"&gt;&amp;quot;logged in&amp;quot;&lt;/span&gt; /etc/networks/*.log
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To search for two or more words, use egrep:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="go"&gt;egrep -w -r &amp;#39;logged in|logged out&amp;#39; /etc/networks/*.log&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To hide warning spam of permission for certain directories being denied, etc, send them to dev/null:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; grep -w -r &lt;span class="s1"&gt;&amp;#39;logged in|logged out&amp;#39;&lt;/span&gt; /etc/networks/*.log &lt;span class="m"&gt;2&lt;/span&gt;&amp;gt;/dev/null
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To make it case insensitive, use -i option:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; grep -i &lt;span class="s2"&gt;&amp;quot;logged in&amp;quot;&lt;/span&gt; /etc/networks/*.log
&lt;/pre&gt;&lt;/div&gt;</content><category term="linux"></category></entry></feed>